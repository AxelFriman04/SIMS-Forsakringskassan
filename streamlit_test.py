#TEST LAYOUT 2  hittas p√•: (http://localhost:8501)
import streamlit as st
import re
from numpy.random import default_rng as rng
import spacy #Ladda ner: py -m pip install spacy, py -m spacy download sv_core_news_sm

# Ladda svenska modeller(k√§nner igen ord med oliak b√∂jningar ex: "hatt" = "hatten")
nlp_sv = spacy.load("sv_core_news_sm")
st.set_page_config(layout="wide")

#Visar metric √§ven om v√§rdet √§r None
def safe_metric(label, value, suffix=""):
    if value is None:
        st.metric(label, "Ej tillg√§nglig")
    else:
        if isinstance(value, (int, float)):
            st.metric(label, f"{value}{suffix}")
        else:
            st.metric(label, str(value))

st.title("Streamlit test")

#delar upp allt i olika columner s√• att de hamnar bredvid varandra!
col1, col2 = st.columns([2, 4])

# ------- Tar bort f√∂ljande h√•rdkodade del vid koppling av compliance checkern och byter ut mot json inport.-------
# exempeldata f√∂r metriker
query = "hur stor blir hatten p√• en karljohansvamp?"
#RAG-svar (simulerat)
rag_answer = "Den har ett vitt √•dern√§t p√• foten och en 10‚Äì25 centimeter stor hatt som varierar i olika nyanser av brunt"
compliance_score = 0.895  # mellan 0 och 1
verdict = "Fully Compliant"
confidence = 0.75
root_causes = [
    "Retrieval narrow or unbalanced; low source diversity.",
    "Potential hallucinations detected in generation step."
]
summary = "Overall compliance verdict generated by the pipeline."
metrics = {
    "ingestion": {"parsing_success_rate": 1.0, "num_chunks": 24, "num_pages": 24,
      "total_chars": 77722, "type": "ingest",
      "doc_id": "0492e4c3-f4d0-45b9-80e8-3c5ffd110ada", "chunk_coverage_pct": 100.0,
      "embedding_fidelity": 0.7022490187829242,
      "metadata_completeness": 1.0},
    "retrieval": { "type": "retrieval",
     "topk_scores": [ 0.7385188638894171, 0.7298134200432586, 0.7134240171369514, 0.7132235772097032, 0.6977011677366977],
     "topk_gap": 0.04081769615271946, "distinct_source_count": 1,"lexical_overlap": 0.2096508221556618,
      "retrieval_latency": 7.071361303329468,"re_rank_delta": 0.07388342601602793, "num_hits": 5, "recall_vs_gold": None},
      "generation": {"token_logprob_stats": {"avg": None,"min": None,"count": 0},
      "generator_declared_citations": [
        "[0492e4c3-f4d0-45b9-80e8-3c5ffd110ada::p1::c0]",
        "[0492e4c3-f4d0-45b9-80e8-3c5ffd110ada::p1::c0]",
        "[0492e4c3-f4d0-45b9-80e8-3c5ffd110ada::p1::c0]",
        "[0492e4c3-f4d0-45b9-80e8-3c5ffd110ada::p1::c0]"
      ],
      "answer_length": 1034,
      "claim_count": 4,
      "preliminary_hallucinations_warnings": [
        "Citations reference non-retrieved chunks."
      ]
    },
    "compliance": {"claim_extraction": {"claim_count": 20},"verification": {"entailment_ratio": 0.9,
    "contradiction_ratio": 0.0,"avg_confidence": 0.889},"num_claims": 20, "num_verified_claims": 20}
}
other={"claims": [],"verified_claims": [],
    "summary": "Overall compliance verdict generated by the pipeline."
}
# ---------------------- Byt ut till hit ----------------

#nyckelord f√∂r s√∂kning
stopwords = {"hur", "p√•", "en", "och", "att", "som", "den", "det", "i", "ett"}
words = re.findall(r"\b[a-z√•√§√∂A-Z√Ö√Ñ√ñ]+\b", query.lower())

doc_q = nlp_sv(query)
# filtrera bort stopwords, icke-alfabetiska tokens och v√§ldigt korta ord
keywords = [
    token.lemma_.lower()
    for token in doc_q
    if token.is_alpha and token.text.lower() not in stopwords and len(token.text) > 2]
#Markerar nyckelord  fr√•n fr√•ga som matchar fr√•gan och svaret med gr√∂n f√§rg.
def highlight_keywords(text, keywords):
    doc = nlp_sv(text)
    highlighted_text = ""
    for token in doc:
        lemma = token.lemma_.lower()
        if lemma in keywords:
            highlighted_text += f"<span style='color:green; font-weight:bold'>{token.text}</span> "
        else:
            highlighted_text += token.text + " "
    return highlighted_text.strip()

# KOLUMN 1: LLM inforamtion + fr√•ga
with col1:
    with st.container(border=True):
        st.subheader("üí¨ Fr√•ga:")
        st.write(query)

        st.subheader("üìã Svar fr√•n RAG-systemet:")
        st.markdown(highlight_keywords(rag_answer, keywords), unsafe_allow_html=True)

# KOLUMN 2: Bed√∂mning fr√•n compilance checker
with col2:
    with st.container(border=True):
        st.subheader("üìä Bed√∂mning")
    # Platsh√•llare: h√•rdkodad procent
        # Omvandla compliance score till procent
        compliance_pct = round(compliance_score * 100, 1)
        st.metric("Compliance Score", f"{compliance_pct}%")
        # Best√§m f√§rg baserat p√• niv√•
        if compliance_score >= 80:
            color = "#4CAF50"  # gr√∂nt
        elif compliance_score >= 50:
            color = "#FFC107"  # gult
        else:
            color = "#F44336"  # r√∂tt
        # Skapa en HTML-stapel som progressbar
        st.markdown(f"""
        <div style="background-color:#e0e0e0; border-radius:10px; padding:3px; width:100%; height:30px;">
            <div style="width:{compliance_pct}%; background-color:{color}; height:100%; border-radius:10px; text-align:center; color:white; font-weight:bold;">
            </div>
        </div>
        """, unsafe_allow_html=True)

        st.write(f"**Verdict:** {verdict}")
        st.write(f"**Confidence:** {confidence:.2f}")
        st.write(f"**Sammanfattning:** {summary}")


        with st.expander("Visa mer information"):
            # Root causes
            st.subheader("Detaljerad analys")
            st.markdown("**Identifierade orsaker:**")
            for cause in root_causes:
                st.markdown(f"- {cause}")

            # Metriker INGESTION
            st.divider()
            st.subheader("Metriker:")
            st.markdown("Fr√•n ingestion:")
            colA, colB, colC = st.columns(3)
            with colA:
                st.metric("Antal chunks:", f"{metrics['ingestion']['num_chunks']}")
                st.metric("Parsing success rate", f"{metrics['ingestion']['parsing_success_rate']*100:.0f}%")
                st.metric("Embedding trohet:", f"{metrics['ingestion']['embedding_fidelity']*100:.0f}%")
            with colB:
                st.metric("Antal sidor:", f"{metrics['ingestion']['num_pages']}")
                st.metric("Totala antalet chars:", f"{metrics['ingestion']['total_chars']}")
            with colC:
                st.metric("Fullst√§ndighet metedata:", f"{metrics['ingestion']['metadata_completeness']*100:.0f}")
                st.metric("byt namn", f"{metrics['ingestion']['chunk_coverage_pct']:.0f}%")
            st.markdown(f"Dokument ID: <span style='font-family:monospace; font-size:14px; color:darkgrey;'>{metrics['ingestion']['doc_id']}</span>", unsafe_allow_html=True)
            st.divider()

            #Metrik RETRIEVAL
            st.markdown("Fr√•n retriver:")
            colD, colE, colF = st.columns(3)
            with colD:
                st.metric("Lexical overlap", f"{metrics['retrieval']['lexical_overlap']*100:.1f}%")
                st.metric("byt namn:", f"{metrics['retrieval']['topk_gap']*100:.0f}%")
                safe_metric("Recall vs Gold", metrics["retrieval"]["recall_vs_gold"])    
            with colE:
                st.metric("Antalet tr√§ffar:", f"{metrics['retrieval']['num_hits']}")
                st.metric("Total tid:", f"{metrics['retrieval']['retrieval_latency']:.2f}s")
            with colF:
                st.metric("bytnamn:", f"{metrics['retrieval']['re_rank_delta']*100:.1f}%")
                st.metric("Antal k√§llor:", f"{metrics['retrieval']['distinct_source_count']}")
            st.divider()

            #Metrik GENERATION
            st.markdown("Fr√•n generering:")
            colG, colH, colI = st.columns(3)
            with colG:
                st.metric("Svarsl√§ngd:", f"{metrics['generation']['answer_length']}")
            with colH:
                st.metric("Antal p√•st√•enden:", f"{metrics['generation']['claim_count']}")
            with colI:
                citations = metrics["generation"]["generator_declared_citations"]
                st.metric("Antal citat", len(citations))
            with st.expander("Visa citerade k√§llor"):
                    for c in citations:
                        st.write(c)
            # Token logprob
            if metrics['generation']["token_logprob_stats"]["avg"] is not None:
                st.metric("Genomsnittlig token-logprob", f"{metrics['generation']['token_logprob_stats']['avg']:.2f}")
            else:
                st.write("Token-logprob-statistik: Ej tillg√§nglig")
            if metrics['generation']["preliminary_hallucinations_warnings"]:
                with st.expander("Hallucinationsvarningar"):
                    for warn in metrics['generation']["preliminary_hallucinations_warnings"]:
                        st.warning(warn) 
            st.divider()
            st.markdown("Fr√•n Compliance-utv√§rdering:")

            # COMPLIANCE v√§rden
            colJ, colK, colL = st.columns(3)
            with colJ:
                safe_metric("Antal claims (extraherade)", metrics["compliance"]["claim_extraction"]["claim_count"])
                safe_metric("Totalt antal claims", metrics["compliance"]["num_claims"])
            with colK:
                safe_metric("Verifierade claims", metrics["compliance"]["num_verified_claims"])
                safe_metric("Entailment ratio", f"{metrics['compliance']['verification']['entailment_ratio']*100:.1f}%")
            with colL:
                safe_metric("Contradiction ratio", f"{metrics['compliance']['verification']['contradiction_ratio']*100:.1f}%")
                safe_metric("Genomsnittligt f√∂rtroende", f"{metrics['compliance']['verification']['avg_confidence']*100:.1f}%")
            st.divider()

            st.subheader("Granskade p√•st√•enden")
            claims_list = other["claims"]
            verified_claims_list = other["verified_claims"]

            colM, colN = st.columns(2)
            with colM:
                st.markdown("**Extraherade p√•st√•enden:**")
                if claims_list:
                    for c in claims_list:
                        st.markdown(f"- {c}")
                else:
                    st.info("Inga extraherade p√•st√•enden tillg√§ngliga.")
            with colN:
                st.markdown("**Verifierade p√•st√•enden:**")
                if verified_claims_list:
                    for v in verified_claims_list:
                        st.markdown(f"- {v}")
                else:
                    st.info("Inga verifierade p√•st√•enden tillg√§ngliga.")
            # Top-k retrieval scores
            st.divider()
            st.markdown("**Top-5 Retrieval-Scores:**")
            st.bar_chart(metrics["retrieval"]["topk_scores"]) 
    